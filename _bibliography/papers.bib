---
---

@article{ibrahim2024hybrid,
  title={Hybrid Deep Learning for Legal Text Analysis: Predicting Punishment Durations in Indonesian Court Rulings},
  author={Ibrahim, Muhammad Amien and Handoyo, Alif Tri and Anggreainy, Maria Susan},
  journal={arXiv preprint arXiv:2410.20104},
  year={2024},
  html={https://arxiv.org/abs/2410.20104},
  abstract = {Limited public understanding of legal processes and inconsistent verdicts in the Indonesian court system led to widespread dissatisfaction and increased stress on judges. This study addresses these issues by developing a deep learning-based predictive system for court sentence lengths. Our hybrid model, combining CNN and BiLSTM with attention mechanism, achieved an R-squared score of 0.5893, effectively capturing both local patterns and long-term dependencies in legal texts. While document summarization proved ineffective, using only the top 30% most frequent tokens increased prediction performance, suggesting that focusing on core legal terminology balances information retention and computational efficiency. We also implemented a modified text normalization process, addressing common errors like misspellings and incorrectly merged words, which significantly improved the model's performance. These findings have important implications for automating legal document processing, aiding both professionals and the public in understanding court judgments. By leveraging advanced NLP techniques, this research contributes to enhancing transparency and accessibility in the Indonesian legal system, paving the way for more consistent and comprehensible legal decisions.},
  selected={true}
}

@article {10.3844/jcssp.2024.819.826,
  article_type = {journal},
  title = {Prompt-Based Data Augmentation with Large Language Models for Indonesian Gender-Based Hate Speech Detection},
  author = {Ibrahim, Muhammad Amien and Faisal, and Sulistiya, Zefanya Delvin and Winarto, Tora Sangputra Yopie},
  volume = {20},
  number = {8},
  year = {2024},
  month = {May},
  pages = {819-826},
  doi = {10.3844/jcssp.2024.819.826},
  url = {https://thescipub.com/abstract/jcssp.2024.819.826},
  abstract = {The increasing amount of content on social media content makes the use of automatic moderation crucial for preserving a healthy online community and reducing the spread of offensive and abusive content, such as hate speech based on gender. Developing automated social media moderation using machine learning demands a large and balanced dataset. However, difficulties such as data scarcity and class imbalance have hindered the development of gender-based hate speech detection on Indonesian Twitter communities. Creating and annotating a new dataset would be time-consuming and costly. One practical alternative is to use data augmentation methods to help address the minority class imbalance in datasets. This study investigates how prompt-based data augmentation may be used with a large language model to provide organic tweet samples for gender-based hate speech detection. Furthermore, the study investigates the preservation of labels in augmented Twitter samples. In comparison to the benchmark back translation approach, the results show that prompt-based data augmentation using a large language model may generate new and organic Twitter samples while keeping labels preserved and avoiding memorization. In conventional machine learning models, prompt-based data augmentation with a large language model shows competitive performance compared to back translation in terms of accuracy metrics. According to these results, using prompting for data augmentation on large language models is an alternative strategy that can provide new, less memorization tweet samples that maintain label integrity while achieving competitive accuracy results.},
  journal = {Journal of Computer Science},
  publisher = {Science Publications},
  selected={true}
}

@inproceedings{hasani2024utterance,
  title={Utterance Intent Recognition for Online Retail},
  author={Hasani, Muhammad Fikri and Purwandari, Kartika and Ibrahim, Muhammad Amien and Arifin, Samsul and Safira, Wanda and Prabaswara, Benedictus},
  booktitle={2024 3rd International Conference on Digital Transformation and Applications (ICDXA)},
  pages={199--204},
  year={2024},
  organization={IEEE}
}

@article {10.3844/jcssp.2023.1222.1230,
  article_type = {journal},
  title = {Exploring Data Augmentation for Gender-Based Hate Speech Detection},
  author = {Ibrahim, Muhammad Amien and Arifin, Samsul and Purwanto , Eko Setyo},
  volume = {19},
  number = {10},
  year = {2023},
  month = {Sep},
  pages = {1222-1230},
  doi = {10.3844/jcssp.2023.1222.1230},
  url = {https://thescipub.com/abstract/jcssp.2023.1222.1230},
  abstract = {Social media moderation is a crucial component to establish healthy online communities and ensuring online safety from hate speech and offensive language. In many cases, hate speech may be targeted at specific gender which could be expressed in many different languages on social media platforms such as Indonesian Twitter. However, difficulties such as data scarcity and the imbalanced gender-based hate speech dataset in Indonesian tweets have slowed the development and implementation of automatic social media moderation. Obtaining more data to increase the number of samples may be costly in terms of resources required to gather and annotate the data. This study looks at the usage of data augmentation methods to increase the amount of textual dataset while keeping the quality of the augmented data. Three augmentation strategies are explored in this study: Random insertion, back translation, and a sequential combination of back translation and random insertion. Additionally, the study examines the preservation of the increased data labels. The performance result demonstrates that classification models trained with augmented data generated from random insertion strategy outperform the other approaches. In terms of label preservation, the three augmentation approaches have been shown to offer enough label preservation without compromising the meaning of the augmented data. The findings imply that by increasing the amount of the dataset while preserving the original label, data augmentation could be utilized to solve issues such as data scarcity and dataset imbalance.},
  journal = {Journal of Computer Science},
  publisher = {Science Publications},
  selected={true}
}

@inproceedings{sagala2022comparative,
  title={A Comparative Study of Different Boosting Algorithms for Predicting Olympic Medal},
  author={Sagala, Noviyanti TM and Ibrahim, Muhammad Amien},
  booktitle={2022 IEEE 8th International Conference on Computing, Engineering and Design (ICCED)},
  pages={1--4},
  year={2022},
  organization={IEEE}
}

@inproceedings{ibrahim2022separating,
  title={Separating hate speech from abusive language on indonesian twitter},
  author={Ibrahim, Muhammad Amien and Sagala, Noviyanti Tri Maretta and Arifin, Samsul and Nariswari, Rinda and Murnaka, Nerru Pranuta and Prasetyo, Puguh Wahyu},
  booktitle={2022 International Conference on Data Science and Its Applications (ICoDSA)},
  pages={187--191},
  year={2022},
  organization={IEEE},
  html = {https://www.researchgate.net/publication/362950867_Separating_Hate_Speech_from_Abusive_Language_on_Indonesian_Twitter},
  abstract = {Social media is an effective tool for connecting with people and distributing information. However, many people often use social media to spread hate speech and abusive languages. In contrast to hate speech, abusive languages are frequently used as jokes with no purpose of offending individuals or groups, even though they may contain profanities. As a result, the distinction between hate speech and abusive language is often blurred. In many cases, individuals who spread hate speech may be prosecuted as it has legal implications. Previous research has focused on binary classification of hate speech and normal tweets. This study aims to classify hate speech, abusive language, and normal messages on Indonesian Twitter. Several machine learning models, such as logistic regression and BERT models, are utilized to accomplish text classification tasks. The model's performance is assessed using the F1-Score evaluation metric. The results show that BERT models outperform other models in terms of F1-Score, with the BERT-indobenchmark model, which was pretrained on social media text data, achieving the highest F1-Score of 85.59. This also demonstrates that pretraining the BERT model using social media data improves the classification model significantly. Developing such classification model that can distinguish between hate speech and abusive language would help individuals in preventing the spread of hate speech that has legal implications.},
  selected={true}
}

@article{ibrahim2022explainable,
  title={An explainable AI model for hate speech detection on Indonesian twitter},
  author={Ibrahim, Muhammad Amien and Arifin, Samsul and Yudistira, I Gusti Agung Anom and Nariswari, Rinda and Abdillah, Abdul Azis and Murnaka, Nerru Pranuta and Prasetyo, Puguh Wahyu},
  journal={CommIT (Communication and Information Technology) Journal},
  volume={16},
  number={2},
  pages={175--182},
  html = {https://journal.binus.ac.id/index.php/commit/article/view/8343},
  abstract = {To avoid citizen disputes, hate speech on social media, such as Twitter, must be automatically detected. The current research in Indonesian Twitter focuses on developing better hate speech detection models. However, there is limited study on the explainability aspects of hate speech detection. The research aims to explain issues that previous researchers have not detailed and attempt to answer the shortcomings of previous researchers. There are 13,169 tweets in the dataset with labels like “hate speech” and “abusive language”. The dataset also provides binary labels on whether hate speech is directed to individual, group, religion, race, physical disability, and gender. In the research, classification is performed by using traditional machine learning models, and the predictions are evaluated using an Explainable AI model, such as Local Interpretable Model-Agnostic Explanations (LIME), to allow users to comprehend why a tweet is regarded as a hateful message. Moreover, models that perform well in classification perceive incorrect words as contributing to hate speech. As a result, such models are unsuitable for deployment in the real world. In the investigation, the combination of XGBoost and logical LIME explanations produces the most logical results. The use of the Explainable AI model highlights the importance of choosing the ideal model while maintaining users’ trust in the deployed model.}
  year={2022}
}
